{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d391bbef",
   "metadata": {},
   "source": [
    "# <font color=#bf7c2a> **Aula 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898612e0",
   "metadata": {},
   "source": [
    "#### <font color=#9c9c9c> Desafio **EXTRA** referente à Aula 3. \"Dados textuais\" do curso **\"Pandas: transformação e manipulação de dados\"**, da *Alura*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979406a",
   "metadata": {},
   "source": [
    "Aprendemos a manipular os elementos textuais com o comando `str`. Depois, utilizamos de regex para limpar elementos indesejados no texto e, por fim, transformamos o texto tratado em uma lista, construindo um token.\n",
    "\n",
    "Durante as aulas, transformamos duas colunas, `descricao_local` e `comodidades`, buscando a tokenização. Mas ainda falta a coluna **`descricao_vizinhanca`**, que também vale ser transformada.\n",
    "\n",
    "Portanto, nessa atividade, proponho que você faça o processo de tokenização para a coluna `descricao_vizinhanca` presente no conjunto de dados [dados_hospedagem.json](https://cdn3.gnarususercontent.com.br/2928-transformacao-manipulacao-dados/dados_hospedagem.json).\n",
    "\n",
    "Fique à vontade para seguir com os mesmos passos dados em aula ou, se preferir, realizar outros aprimoramentos, como a remoção de algum caractere ou de stopwords. Na seção “Opinião da pessoa instrutora”, você vai encontrar uma possibilidade de resolução para essa atividade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12398f7",
   "metadata": {},
   "source": [
    "### <font color=#c09c6f> **Carregando e preparando os dados para o tratamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a biblioteca Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados para um dataframe\n",
    "dados = pd.read_json('dados_hospedagem.json')\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza o dataframe\n",
    "dados = pd.json_normalize(dados['info_moveis'])\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d177bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazena as colunas do dataframe em um lista\n",
    "colunas = list(dados.columns)\n",
    "colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados numéricos presentes em listas\n",
    "dados = dados.explode(colunas[3:])\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseta a coluna de index do dataframe\n",
    "dados.reset_index(inplace=True, drop=True)\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb0bbf",
   "metadata": {},
   "source": [
    "### <font color=#c09c6f> **Tokenização da coluna `descricao_vizinhanca`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a coluna \"descricao_vizinhanca\"\n",
    "dados['descricao_vizinhanca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e675ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passa todas as letras da coluna para minúsculo\n",
    "dados['descricao_vizinhanca'] = dados['descricao_vizinhanca'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39098405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica expressão regular para retirar os caracteres indesejados\n",
    "dados['descricao_vizinhanca'] = dados['descricao_vizinhanca'].str.replace('[^a-zA-Z0-9\\-\\']', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove hífens de palavras não compostas\n",
    "dados['descricao_vizinhanca'] = dados['descricao_vizinhanca'].str.replace('(?<!\\w)-(?!\\w)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove vírgulas da coluna\n",
    "dados['descricao_vizinhanca'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbe12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a tokenização na coluna\n",
    "dados['descricao_vizinhanca'] = dados['descricao_vizinhanca'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfa224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a coluna após a tokenização\n",
    "dados['descricao_vizinhanca']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9099a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
